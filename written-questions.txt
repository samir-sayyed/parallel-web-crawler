Written Questions

Q1. Run the web crawler using the configurations located at src/main/config/written_question_1a.json and
    src/main/config/written_question_1b.json. The only difference between these configurations is that one always uses
    the sequential crawler and the other always uses the parallel crawler. Inspect the profile output in
    profileData.txt.

    If you are using a multi-processor computer, you should notice that SequentialWebCrawler#crawl and
    ParallelWebCrawler#crawl took about the same amount of time, but PageParserImpl#parse took much longer when run with
    the ParallelWebCrawler.

    Why did the parser take more time when run with ParallelWebCrawler?
    It is because in case of parallel crawler it divides work in many parts so parser need to travel more


Q2. Your manager ran your crawler on her old personal computer, using the configurations from Q1, and she notices that
    the sequential crawler actually outperforms the parallel crawler. She would like to know why.

    (a) Suggest one reason why the sequential web crawler was able to read more web pages than the parallel crawler.
        (Hint: Try setting "parallelism" to 1 in the JSON configs to simulate your manager's computer.)

        Ans:- because her computer is having only one core so it can not take of advantage of multithreading

    (b) Suggest one scenario in which the parallel web crawler will almost certainly perform better than the sequential
        crawler. Why will it perform better?

        Ans:- if our system is supports multithreading and having core more than one then parallel crawler perform very well as compare sequential.
                Due to multithreading our work is divided and different threads work on different processes.


Q3. Analyze your method profiler through the lens of Aspect Oriented Programming, by answering the following questions:

    (a) What cross-cutting concern is being addressed by the com.udacity.webcrawler.profiler.Profiler class?

    Ans:- Profiler measures the performance of the web crawler

    (b) What are the join points of the Profiler in the web crawler program?

    Ans:- The method which having @Profiled annotation is join point


Q4. Identify three (3) different design patterns used in this project, and explain which interfaces, classes, and/or
    libraries use or implement those design patterns.

    For each pattern, name one thing about the pattern that you LIKED, and one thing you DISLIKED. If you did not like
    anything, you can name two things you disliked.

    Proxy pattern :- we are using this pattern in ProfilerImpl class it act as intermediate between two classes so by using it we
                     hide underlying complexity another thing we can do that we can add layer of security, but it makes our classes more complex

   Builder pattern :- we are using this pattern in Configuration loader and Crawl result its simplifies the constructor If user forgot
                      to send some arguments to constructor or messed up with sequence this pattern solves this problem and on another
                      side we need to write some extra code to achieve it

   Dependency Injection:- we are using this pattern in WebCrawlerMain class, this pattern helps in making classes loosely coupled also
                          it makes classes independent of its dependencies, but it makes our classes more complex
